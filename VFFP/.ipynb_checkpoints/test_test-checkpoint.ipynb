{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ef596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m tensorboard.main --logdir VPTR_ckpts/MNIST_ResNetAE_MSEGDLgan_tensorboard\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import tifffile\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "from customdatasets import SegmentationData\n",
    "from model import VPTREnc, VPTRDec, VPTRDisc, init_weights\n",
    "from model import GDL, MSELoss, L1Loss, GANLoss\n",
    "from utils import get_dataloader\n",
    "from utils import VidCenterCrop, VidPad, VidResize, VidNormalize, VidReNormalize, VidCrop, VidRandomHorizontalFlip, VidRandomVerticalFlip, VidToTensor\n",
    "from utils import visualize_batch_clips, save_ckpt, load_ckpt, set_seed, AverageMeters, init_loss_dict, update_summary, write_summary, resume_training\n",
    "from utils import set_seed\n",
    "\n",
    "set_seed(2021)\n",
    "\n",
    "def cal_lossD(VPTR_Disc, fake_imgs, real_imgs, lam_gan):\n",
    "    pred_fake = VPTR_Disc(fake_imgs.detach().flatten(0, 1))\n",
    "    loss_D_fake = gan_loss(pred_fake, False)\n",
    "    # Real\n",
    "    pred_real = VPTR_Disc(real_imgs.flatten(0,1))\n",
    "    loss_D_real = gan_loss(pred_real, True)\n",
    "    # combine loss and calculate gradients\n",
    "    loss_D = (loss_D_fake + loss_D_real) * 0.5 * lam_gan\n",
    "\n",
    "    return loss_D, loss_D_fake, loss_D_real\n",
    "    \n",
    "def cal_lossG(VPTR_Disc, fake_imgs, real_imgs, lam_gan):\n",
    "    pred_fake = VPTR_Disc(fake_imgs.flatten(0, 1))\n",
    "    loss_G_gan = gan_loss(pred_fake, True)\n",
    "    \n",
    "    AE_MSE_loss = mse_loss(fake_imgs, real_imgs)\n",
    "    AE_GDL_loss = gdl_loss(real_imgs, fake_imgs)\n",
    "    #AE_L1_loss = l1_loss(fake_imgs, real_imgs)\n",
    "\n",
    "    loss_G = lam_gan * loss_G_gan + AE_MSE_loss + AE_GDL_loss\n",
    "\n",
    "    return loss_G, loss_G_gan, AE_MSE_loss, AE_GDL_loss\n",
    "\n",
    "def single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, optimizer_G, optimizer_D, sample, device, train_flag = True):\n",
    "    past_frames, future_frames = sample\n",
    "    past_frames = past_frames.to(device)\n",
    "    future_frames = future_frames.to(device)\n",
    "    x = torch.cat([past_frames, future_frames], dim = 1)\n",
    "    \n",
    "    if train_flag:\n",
    "        VPTR_Enc = VPTR_Enc.train()\n",
    "        VPTR_Enc.zero_grad()\n",
    "        VPTR_Dec = VPTR_Dec.train()\n",
    "        VPTR_Dec.zero_grad()\n",
    "\n",
    "        \n",
    "        rec_frames = VPTR_Dec(VPTR_Enc(x))\n",
    "\n",
    "        #update discriminator\n",
    "        VPTR_Disc = VPTR_Disc.train()\n",
    "        for p in VPTR_Disc.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        VPTR_Disc.zero_grad(set_to_none=True)\n",
    "\n",
    "        loss_D, loss_D_fake, loss_D_real = cal_lossD(VPTR_Disc, rec_frames, x, lam_gan)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        #update autoencoder (generator)\n",
    "        for p in VPTR_Disc.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        loss_G, loss_G_gan, AE_MSE_loss, AE_GDL_loss = cal_lossG(VPTR_Disc, rec_frames, x, lam_gan)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "    else:\n",
    "        VPTR_Enc = VPTR_Enc.eval()\n",
    "        VPTR_Dec = VPTR_Dec.eval()\n",
    "        VPTR_Disc = VPTR_Disc.eval()\n",
    "        with torch.no_grad():\n",
    "            rec_frames = VPTR_Dec(VPTR_Enc(x))\n",
    "            loss_D, loss_D_fake, loss_D_real = cal_lossD(VPTR_Disc, rec_frames, x, lam_gan)\n",
    "            loss_G, loss_G_gan, AE_MSE_loss, AE_GDL_loss = cal_lossG(VPTR_Disc, rec_frames, x, lam_gan)\n",
    "        \n",
    "    iter_loss_dict = {'AEgan': loss_G_gan.item(), 'AE_MSE': AE_MSE_loss.item(), 'AE_GDL': AE_GDL_loss.item(), 'AE_total': loss_G.item(), 'Dtotal': loss_D.item(), 'Dfake':loss_D_fake.item(), 'Dreal':loss_D_real.item()}\n",
    "    \n",
    "    return iter_loss_dict\n",
    "\n",
    "def show_samples(VPTR_Enc, VPTR_Dec, sample, save_dir, renorm_transform):\n",
    "    VPTR_Enc = VPTR_Enc.eval()\n",
    "    VPTR_Dec = VPTR_Dec.eval()\n",
    "    with torch.no_grad():\n",
    "        past_frames, future_frames = sample\n",
    "        past_frames = past_frames.to(device)\n",
    "        future_frames = future_frames.to(device)\n",
    "\n",
    "        past_gt_feats = VPTR_Enc(past_frames)\n",
    "        future_gt_feats = VPTR_Enc(future_frames)\n",
    "\n",
    "        rec_past_frames = VPTR_Dec(past_gt_feats)\n",
    "        rec_future_frames = VPTR_Dec(future_gt_feats)\n",
    "\n",
    "        N = future_frames.shape[0]\n",
    "        idx = min(N, 4)\n",
    "        visualize_batch_clips(past_frames[0:idx, :, ...], rec_future_frames[0:idx, :, ...], rec_past_frames[0:idx, :, ...], save_dir, renorm_transform, desc = 'ae')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run = \"1\"\n",
    "\n",
    "    ckpt_save_dir = Path('./VPTR_chkpts/MNIST_ResNetAE_MSEGDLgan_ckpt/')\n",
    "    tensorboard_save_dir = Path('./VPTR_chkpts/MNIST_ResNetAE_MSEGDLgan_tensorboard/'+run)\n",
    "    \n",
    "    resume_ckpt = ckpt_save_dir.joinpath('epoch_2.tar')\n",
    "    #resume_ckpt = None\n",
    "    start_epoch = 2\n",
    "\n",
    "    summary_writer = SummaryWriter(tensorboard_save_dir.absolute().as_posix())\n",
    "    num_past_frames = 10\n",
    "    num_future_frames = 10\n",
    "    encH, encW, encC = 8, 8, 528\n",
    "    img_channels = 1 #3 channels for BAIR datset\n",
    "    epochs = 50\n",
    "    N = 1\n",
    "    AE_lr = 2e-4\n",
    "    lam_gan = 0.01\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    #####################Init Dataset ###########################\n",
    "    data_set_name = 'MNIST' #see utils.dataset\n",
    "    dataset_dir = './MovingMNIST/'\n",
    "    train_loader, val_loader, test_loader, renorm_transform = get_dataloader(data_set_name, N, dataset_dir, num_past_frames, num_future_frames)\n",
    "    \n",
    "    sample_np = tifffile.memmap(\"../dataset-1/210202/normalized/07_baseline_norm.tif\", mode='r')\n",
    "    data_train = SegmentationData(\n",
    "        inputs=sample_np[0:10], augment=None\n",
    "    )\n",
    "    training_dataloader = DataLoader(dataset=data_train, batch_size=1, shuffle=True)\n",
    "    import time\n",
    "    \n",
    "    for sample in iter(training_dataloader):\n",
    " \n",
    "        plt.imshow(sample[0])\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # #####################Init Models and Optimizer ###########################\n",
    "    # VPTR_Enc = VPTREnc(img_channels, feat_dim = encC, n_downsampling = 3).to(device)\n",
    "    # VPTR_Dec = VPTRDec(img_channels, feat_dim = encC, n_downsampling = 3, out_layer = 'Tanh').to(device) #Sigmoid for MNIST, Tanh for KTH and BAIR\n",
    "    # VPTR_Disc = VPTRDisc(img_channels, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d).to(device)\n",
    "    # init_weights(VPTR_Disc)\n",
    "    # init_weights(VPTR_Enc)\n",
    "    # init_weights(VPTR_Dec)\n",
    "\n",
    "    # optimizer_G = torch.optim.Adam(params = list(VPTR_Enc.parameters()) + list(VPTR_Dec.parameters()), lr=AE_lr, betas = (0.5, 0.999))\n",
    "    # optimizer_D = torch.optim.Adam(params = VPTR_Disc.parameters(), lr=AE_lr, betas = (0.5, 0.999))\n",
    "\n",
    "    # Enc_parameters = sum(p.numel() for p in VPTR_Enc.parameters() if p.requires_grad)\n",
    "    # Dec_parameters = sum(p.numel() for p in VPTR_Dec.parameters() if p.requires_grad)\n",
    "    # Disc_parameters = sum(p.numel() for p in VPTR_Disc.parameters() if p.requires_grad)\n",
    "    # print(f\"Encoder num_parameters: {Enc_parameters}\")\n",
    "    # print(f\"Decoder num_parameters: {Dec_parameters}\")\n",
    "    # print(f\"Discriminator num_parameters: {Disc_parameters}\")\n",
    "\n",
    "    # #####################Init Criterion ###########################\n",
    "    # loss_name_list = ['AE_MSE', 'AE_GDL', 'AE_total', 'Dtotal', 'Dfake', 'Dreal', 'AEgan']\n",
    "    # gan_loss = GANLoss('vanilla', target_real_label=1.0, target_fake_label=0.0).to(device)\n",
    "    # loss_dict = init_loss_dict(loss_name_list)\n",
    "    # mse_loss = MSELoss()\n",
    "    # gdl_loss = GDL(alpha = 1)\n",
    "\n",
    "    # if resume_ckpt is not None:\n",
    "    #     loss_dict, start_epoch = resume_training({'VPTR_Enc': VPTR_Enc, 'VPTR_Dec': VPTR_Dec, 'VPTR_Disc': VPTR_Disc}, \n",
    "    #                                             {'optimizer_G': optimizer_G, 'optimizer_D': optimizer_D}, resume_ckpt,\n",
    "    #                                             loss_name_list)\n",
    "\n",
    "    # #####################Training loop ###########################                                            \n",
    "    # for epoch in range(start_epoch+1, start_epoch + epochs+1):\n",
    "    #     epoch_st = datetime.now()\n",
    "    #     #Train\n",
    "    #     EpochAveMeter = AverageMeters(loss_name_list)\n",
    "    #     with tqdm(enumerate(train_loader, 0), unit=\" batch\", total=len(train_loader)) as tepoch:\n",
    "    #         for idx, sample in tepoch:\n",
    "    #             tepoch.set_description(f\"Epoch {epoch}\")\n",
    "    #             iter_loss_dict = single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, optimizer_G, optimizer_D, sample, device, train_flag = True)\n",
    "    #             EpochAveMeter.iter_update(iter_loss_dict)\n",
    "    #             update_summary(summary_writer, iter_loss_dict, idx, train_flag = True)\n",
    "    #             tepoch.set_postfix(loss=iter_loss_dict[\"AE_total\"])\n",
    "    #             sleep(0.1)\n",
    "    #         write_summary(summary_writer, loss_dict, train_flag = True)\n",
    "\n",
    "    #         loss_dict = EpochAveMeter.epoch_update(loss_dict, epoch, train_flag = True)\n",
    "            \n",
    "    #         show_samples(VPTR_Enc, VPTR_Dec, sample, ckpt_save_dir.joinpath(f'train_gifs_epoch{epoch}'), renorm_transform)\n",
    "            \n",
    "    #         #validation\n",
    "    #         EpochAveMeter = AverageMeters(loss_name_list)\n",
    "    #         for idx, sample in enumerate(val_loader, 0):\n",
    "    #             iter_loss_dict = single_iter(VPTR_Enc, VPTR_Dec, VPTR_Disc, optimizer_G, optimizer_D, sample, device, train_flag = False)\n",
    "    #             EpochAveMeter.iter_update(iter_loss_dict)\n",
    "    #         loss_dict = EpochAveMeter.epoch_update(loss_dict, epoch, train_flag = False)\n",
    "    #         write_summary(summary_writer, loss_dict, train_flag = False)\n",
    "            \n",
    "    #         save_ckpt({'VPTR_Enc': VPTR_Enc, 'VPTR_Dec': VPTR_Dec, 'VPTR_Disc': VPTR_Disc}, \n",
    "    #                 {'optimizer_G': optimizer_G, 'optimizer_D': optimizer_D}, \n",
    "    #                 epoch, loss_dict, ckpt_save_dir)\n",
    "    #         for idx, sample in enumerate(test_loader, random.randint(0, len(test_loader) - 1)):\n",
    "    #             show_samples(VPTR_Enc, VPTR_Dec, sample, ckpt_save_dir.joinpath(f'test_gifs_epoch{epoch}'), renorm_transform)\n",
    "    #             break\n",
    "                \n",
    "    #         epoch_time = datetime.now() - epoch_st\n",
    "    #         print(f'epoch {epoch}', EpochAveMeter.meters['AE_total'])\n",
    "    #         print(f\"Estimated remaining training time: {epoch_time.total_seconds()/3600. * (start_epoch + epochs - epoch)} Hours\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b092d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
